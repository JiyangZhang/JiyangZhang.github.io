Feb 29:
- etestgen:
  - find examples where evosuite or randoop is able to generate e-tests
  - make a pass to the paper
- presentation:
  - write script for presentation
  - prepare for demo
- paper:
  - Code-Aware Prompting


Feb 28:
- etestgen:
  + create examples
  + check with Yuki
- presentation:
  + prepare for the presentation
  + try huggingface animation
- CoditLlama:
  + see how multi-node work


Feb 27:
- etestgen:
  + update randoop and evosuite results
  + update table of projects
  + update 13b results
  - ask Milos to check paper
- RL:
  - finish TD learning
- paper:
  - Code-Aware Prompting

Feb 26:
+ etestgen:
  + update TODO, check the entire paper
  + (lauched) start gen on 13B models and eval
  + Ask Milos next step
+ CoditLlama:
  + try multi node training (waiting still)
- RL:
  - read TD learning
+ Paper:
  + watch Shunyu's talk

Feb 23:
- etestgen:
  -

Feb 22:
+ CoditLlama:
  * re-train with new dataset
- etestgen:
  + update tables
  + check generated e-tests
    - write script
    - prepare examples
+ Seminar:
  - read paper and leave comments
- RL:
  - finish MC methods


Feb 21:
- etestgen:
  + compute throw stmt coverage for tools.
  + compute throw stmt coverage for our models.
  + re-run nestack2e-all-no-name
  + start run rq2 with all ne-test
- RL:
  + read books and see slides
  
Feb 20:
+ RL: (1.5h)
  - read books
- etestgen:
  - add results to paper (1h)
  - inspect generations and check with Milos (2h)
- CoditLlama (2h):
  - figure out why generation is bad with java

Feb 19:
+ etestgen (3h):
  + check and generate tool results
  + process sample 5 results and add to paper
+ CoditLlama (2h):
  + start generation and compute metrics
+ RL (2h):
  + watch videos and read book

Feb 18:
- etestgen (3h):
  - start running condition + 5 sample
  - analyze the tool results
- CoditLlama (1h):
  - start generation

Feb 15:
- CoditLlama (2h)
  - try output: unifed_diff + output
  - try eval on latest checkpoint

Feb 8:
- etestgen (2h)
  - rq2 results
  - write paper
  - meeting
- slides (4h):
  - write script
  - remake slides
- interview:
  - prepare LM knowledge
  - collect research ideas

Feb 6:
- etestgen (4h)
  - compute metric towards rq2
  - start inference on condition model
  - throw statement coverage?
- slides:
  - practice at least twice
- interview:
  - prepare interview, ML knowledge, system design

Feb 5:
+ etestgen: (2h)
  + dataset for rq2
  + start training models on new dataset rq2
  + update metric
+ slides: (2h)
  + make slides and practice
+ RL: (2h)
  + wactch lectures

Jan 14:
- prepare results for the setting we discussed on Fri
- finish reading chapters in the RL book

Nov 21:
- etestgen
  - update script for data collection:
    + collect source code for all methods.
      - check if there does not exist corresponding source code
    - include the called line number in stack trace.
    - manually check each stack trace if the throw statement is not in the last called method.
   
  

Nov 20:
- etestgen:
  + summarize the ablations and results
  + manually try prompts
  + come up with ideas
  - add text to the paper
- intern:
  - read NLP interview questions
  - apply new positions (at least 2)
- look at the materials for fellowship

Nov 7:
- etestgen:
  - eval the generated tests
    - prepare the scripts and data
    - similarity metrics
    - runtime metrics
- qa:
  - investigate the collected data, update the script
  
Nov 6:
- etestgen:
  + new test data stats table
  + compare new test data with covstack2e test data
  + Extract the possible useful test context can we provide test file context given the same mut?
  + run inference on different data
- qa:
  + write script to collect dataset

Oct 20:
- etestgen:
  + prepare script for collecting new ne2e dataset
  - recreate the runtime metrics table
  - launch combinition exps

Oct 19:
+ etestgen:
  + finish script to recollect ne pairs
    + debug and check examples
- qa:
  + check the script

Oct 16:
- etestgen:
  - prepare meeting doc
  - regex to match expected exception
  - see stack2e results
  - check dataset
- seminar
  - read paper

Oct 11:
- etestgen:
  - launch ne2e-one exp
  - analyze the mut2e results
- qa:
  - see results

Oct 10:
- etestgen:
  - prepare doc:
    - stats for ne2e-full
    - metrics ne2e
    - val results mut2e-codellama
- qa:
  - write a test for the script

Oct 9:
- etestgen:
  + create ne2e-one dataset (sample one example from netest)
  + split ne2e-one
  - study deepspeed
+ qa:
  + finish script and test it on one project
  + start running on 1.5k projects

Oct 5:
- etestgen:
  + collect ne2e dataset
  + design prompt for ne2e data
  + split ne2e (randomly select 5 ne tests)
  - check 200 call trace examples.
  - conditions:
    - use together ai to get conditions from Larger model.
    - input includes conditions or output includes conditions

Oct 4:
+ etestgen:
  + meeting
  + script to collect ne data
+ watch NJU course

Oct 3:
+ etestgen:
  + runtime metrics
  * ne2e data collection
+ send emails
+ CSAPP:
  + shell lab

Sep 21:
- etestgen:
  * run data collection and make sure it is correct
  - start to collect ne-e dataset
  + finish script to compute compilable and runnable metrics
- CSAPP:
  - start on shell lab

Sep 20:
+ etestgen:
  + finish etest collection and provide stats
  + present codellama results
  + prepare meeting docs and plan
  
Sep 19:
- etestgen:
  + collect data script on more projects
  + test script for ne2e data.
  - rethink: distillation, instruction-finetuning
+ csapp:
  + check lab


Sep 18:
- etestgen:
  * collect data script on more projects
  - test script for ne2e data.
  - rethink: distillation, instruction-finetuning
- csapp:
  - check lab

Sep 14:
+ paper reading (RAG)
+ re-think the project

Sep 13:
+ etestgen:
  + get results for the current results
  + make a report for meeting
- dataset:
  - check the script
- csapp finish exception video

Sep 12:
+ etestgen:
  + finish generate with call trace:
    + figure out token number, get stats
    + generate response with few examples
    + run and eval
  + stats:
    + # etest
    + # checked and # unchecked
    + # have stack trace
    + avg. len stack trace
+ benchmark:
  + take a look at existing benchmark
+ csapp


Sep 11:
+ etestgen:
  + ensure dataset is corrected collected
  + get stats, and exp results
    + try chatgpt with traces
+ deltr:
  + add TODO to opensource, prepare data
  
Sep 8:
+ etestgen:
  + prepare demo, figure out bug
- QA:
  - check Pengyu's dataset
- read one paper

Sep 7:
+ etestgen:
  + setup script to call openai api
    
Sep 6
+ etestgen:
  + run scripts on more projects
  + run examples from 2 projects, prepare for meeting
+ CSAPP

Sep 5
- etestgen:
  + run scripts on more projects
  + play with playground for collected data
- fse23
  - prepare for the code
  
Aug 31:
+ etestgen
  + fix bug, collect dataset
+ fse23
  + make a pass
+ CSAPP video

Aug 30:
- etestgen
  + run code and fix bug
  - create a small dataset
- read paper for course
- CSAPP video


Aug 29:
+ Get familiar with code on etestgen
+ FSE camera-ready random things
+ take course CSAPP watch video

Aug 22:
1. FSE camera-ready:
   1) update cross-project results
   2) finish the new table
   3) set up script for chatgpt results
